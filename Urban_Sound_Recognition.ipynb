{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to the Urban Sound Recognizer\n",
    "### In this notebook we are going to explore the urban sound dataset and create a deep learning model to recognize the different sounds\n",
    "\n",
    "#### Let's start by importing our libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from keras.layers import Conv1D, MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import BatchNormalization\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy.signal import decimate\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import math\n",
    "import keras\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's read our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = './input/train/Train'\n",
    "df = pd.read_csv('./input/train/train.csv')\n",
    "df['file'] = df['ID'].apply(lambda x: data_folder+'/'+str(x)+'.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our target is categorical so we are going to use label encoder and turn it into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           5435\n",
       "unique            10\n",
       "top       jackhammer\n",
       "freq             668\n",
       "Name: Class, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df[\"Class_id\"] = label_encoder.fit_transform(df['Class'])\n",
    "df['Class'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2)\n",
    "\n",
    "i = 0\n",
    "train, test = train.reset_index(drop=\"index\"), test.reset_index(drop=\"index\")\n",
    "X_train, y_train = train['file'], train['Class_id']\n",
    "X_test, y_test = test['file'], test['Class_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's read the sound wave data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>framerate</th>\n",
       "      <th>channel</th>\n",
       "      <th>sample</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "      <td>1087.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>47235.073597</td>\n",
       "      <td>1.920883</td>\n",
       "      <td>170096.017479</td>\n",
       "      <td>3.621208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12855.979028</td>\n",
       "      <td>0.270045</td>\n",
       "      <td>63506.586591</td>\n",
       "      <td>0.958603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2205.000000</td>\n",
       "      <td>0.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>44100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>176400.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>44100.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>176400.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>48000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>192000.000000</td>\n",
       "      <td>4.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>384000.000000</td>\n",
       "      <td>4.007937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          framerate      channel         sample       length\n",
       "count   1087.000000  1087.000000    1087.000000  1087.000000\n",
       "mean   47235.073597     1.920883  170096.017479     3.621208\n",
       "std    12855.979028     0.270045   63506.586591     0.958603\n",
       "min     8000.000000     1.000000    2205.000000     0.050000\n",
       "25%    44100.000000     2.000000  176400.000000     4.000000\n",
       "50%    44100.000000     2.000000  176400.000000     4.000000\n",
       "75%    48000.000000     2.000000  192000.000000     4.000000\n",
       "max    96000.000000     2.000000  384000.000000     4.007937"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_channels = [sf.read(f, dtype='float32')[0].shape\n",
    "                   for f in X_test]\n",
    "\n",
    "framerates = [sf.read(f, dtype='float32')[1]\n",
    "              for f in X_test]\n",
    "\n",
    "channels = [1 if len(x)==1 else x[1] for x in sample_channels]\n",
    "\n",
    "samples = [x[0] for x in sample_channels]\n",
    "length = np.array(samples) / np.array(framerates)\n",
    "\n",
    "pd.DataFrame({'framerate': framerates, 'channel':channels, \n",
    "             'sample': samples, 'length': length}).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Given the size of our data we are going to need generators for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLASSES = 10\n",
    "RATE = 8000\n",
    "CHANNELS = 1\n",
    "LENGTH = 4\n",
    "SAMPLES = RATE * LENGTH\n",
    "\n",
    "def proc_sound(data, rate):\n",
    "    data = decimate(data, rate//RATE, axis=0)\n",
    "    if len(data.shape) == 2:\n",
    "        data = np.sum(data, axis=1)\n",
    "    pad = SAMPLES - len(data)\n",
    "    if pad > 0:\n",
    "        data = np.pad(data, ((0, pad)), mode = 'wrap')\n",
    "    else:\n",
    "        data = data[:SAMPLES]\n",
    "    return data.reshape((-1, 1))\n",
    "\n",
    "def train_generator(files, labels, augments, per_batch):\n",
    "    while True:\n",
    "        for i in range(0, len(files), per_batch):\n",
    "            signals = []\n",
    "            _labels = []\n",
    "            for j in range(i, min(len(files), i+per_batch)):\n",
    "                file = files[j]\n",
    "                label = labels[j]\n",
    "                data, rate = sf.read(file, dtype='float32')\n",
    "                data = proc_sound(data, rate)\n",
    "                for _ in range(augments+1):\n",
    "                    roll = np.roll(data, np.random.randint(0, SAMPLES))\n",
    "                    signals.append(roll)\n",
    "                    _labels.append(label)\n",
    "            yield np.array(signals), np.array(_labels)\n",
    "            \n",
    "def test_generator(files, labels, per_batch):\n",
    "    while True:\n",
    "        signals = []\n",
    "        _labels = []\n",
    "        for i in range(0, per_batch):\n",
    "            j = np.random.randint(0, len(files))\n",
    "            file = files[j]\n",
    "            label = labels[j]\n",
    "            data, rate = sf.read(file, dtype='float32')\n",
    "            data = proc_sound(data, rate)\n",
    "            signals.append(np.roll(data, np.random.randint(0, SAMPLES)))\n",
    "            _labels.append(label)\n",
    "        yield np.array(signals), np.array(_labels)\n",
    "        \n",
    "def steps_per_epoch(total, batch):\n",
    "    return int(math.ceil(total / batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 6396, 30)          780       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 6396, 30)          120       \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 1276, 50)          28550     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 1276, 50)          200       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 63800)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               8166528   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 8,197,468\n",
      "Trainable params: 8,197,308\n",
      "Non-trainable params: 160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(30,\n",
    "                kernel_size = 25,\n",
    "                strides = 5,\n",
    "                activation='relu',\n",
    "                input_shape=(SAMPLES, CHANNELS,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(50,\n",
    "                kernel_size = 19,\n",
    "                strides = 5,\n",
    "                activation='relu',\n",
    "                input_shape=(SAMPLES, CHANNELS,)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(N_CLASSES, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's compile it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "             optimizer=Adam(0.01),\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's fit it using the generator we previously created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "44/44 [==============================] - 114s 3s/step - loss: 13.9939 - acc: 0.1141\n",
      "Epoch 2/10\n",
      "44/44 [==============================] - 117s 3s/step - loss: 14.0955 - acc: 0.1252\n",
      "Epoch 3/10\n",
      "44/44 [==============================] - 119s 3s/step - loss: 13.9590 - acc: 0.1340\n",
      "Epoch 4/10\n",
      "44/44 [==============================] - 117s 3s/step - loss: 13.9409 - acc: 0.1350\n",
      "Epoch 5/10\n",
      "44/44 [==============================] - 113s 3s/step - loss: 13.9609 - acc: 0.1337\n",
      "Epoch 6/10\n",
      "44/44 [==============================] - 110s 2s/step - loss: 14.0248 - acc: 0.1299\n",
      "Epoch 7/10\n",
      "44/44 [==============================] - 106s 2s/step - loss: 14.0086 - acc: 0.1308\n",
      "Epoch 8/10\n",
      "44/44 [==============================] - 106s 2s/step - loss: 14.0375 - acc: 0.1291\n",
      "Epoch 9/10\n",
      "44/44 [==============================] - 114s 3s/step - loss: 14.0413 - acc: 0.1289\n",
      "Epoch 10/10\n",
      "44/44 [==============================] - 111s 3s/step - loss: 13.9971 - acc: 0.1316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1b5825f8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_batch = 100\n",
    "epochs = 10\n",
    "\n",
    "model.fit_generator(generator=train_generator(X_train, y_train, 1, per_batch),\n",
    "                   steps_per_epoch=steps_per_epoch(len(X_train), per_batch),\n",
    "                   epochs=epochs,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And finally let's evaluate it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 17s 2s/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate_generator(test_generator(X_test,\n",
    "                                    y_test, \n",
    "                                    per_batch),\n",
    "                    steps=steps_per_epoch(len(X_test), per_batch),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13.758993755687367, 0.14636363834142685]\n"
     ]
    }
   ],
   "source": [
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
